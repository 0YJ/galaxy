{"version":3,"sources":["mvc/history/job-dag.js"],"names":["_super","_graph2","default","Graph","JobDAG","options","self","this","filters","_historyContentsMap","_toolMap","_outputIdToJobMap","filteredSetMetadata","dataKeys","call","_","omit","noOutputJobs","constructor","prototype","init","defaults","excludeSetMetadata","_initFilters","_init","push","jobData","job","tool_id","id","filteredErroredJobs","state","isArray","debug","length","read","data","has","historyContents","tools","preprocessJobs","jobs","createGraph","_filterJobs","preprocessHistoryContents","info","forEach","i","content","clone","preprocessTools","_preprocessTools","each","_preprocessJobs","_jobsData","sort","map","preprocessJob","_sort","cmpCreate","b","a","create_time","_preprocessJob","inputs","_processInputs","size","noInputJobs","outputs","_processOutputs","tool","__processInputs","inputMap","nameInJob","input","_validateInputOutput","name","inputOutput","JSON","stringify","src","Error","output","outputMap","filter","j","_filterJob","index","targetId","jobsData","sourceId","joblessVertex","createVertex","createEdge","inputId","createJobLessVertex","directed","toVerticesAndEdges","contentId","mangledId","bCreateTime","weakComponentGraphArray","dag","weakComponents","component","vertices","_jobsDataMap","jobsDataMap","aCreateTime"],"mappings":"8NAIIA,EAASC,EAAAC,QAAMC,MAKfC,EAAS,SAASC,GAClBA,EAAUA,MACV,IAAIC,EAAOC,KAGXD,EAAKE,WAVTF,EAAIN,aACJM,EAAAG,uBAeIH,EAAKI,YAELJ,EAAKK,qBAbTL,EAAIF,eACAC,EAAAA,gBAiBAC,EAAKM,uBAbLN,EAAAA,uBAEAA,EAAAO,UAAA,OAAA,kBAAA,SACAb,EAAAc,KACAR,GACAA,EACAA,EAAAA,KAAKI,EAAWJ,EAAhBO,UAeIE,EAAEC,KAAKX,EAASC,EAAKO,aAXzBP,EAAAA,UAAKW,IAAAA,EAAAA,QAAed,OAePe,YAAcd,GAX3BE,EAAAA,EAAAA,SAAAA,GASHF,EA5BDe,UAAAC,KAAA,SAAAf,GA6BAD,EAAOe,MAWH,IAAIb,EAAOC,KAFXF,OANJC,EAAAD,QAAAU,EAAAM,SAAAhB,GACAiB,oBAAA,IAEAhB,EAAAE,QAAAF,EAAAiB,eAEAnB,EAAOe,UAAUC,KAAjBN,KAAwBR,EAASkB,GAC7BnB,GAIIiB,EAAAA,UAAAA,aAAoB,WADW,IAAAhB,EAAnCC,KAGAD,KA+BC,OA7BDN,EAAAA,QAAOmB,qBACPb,EAAAM,uBAVJJ,EAAAiB,KAAA,SAAAC,GAqBY,MAA4B,qBAAxBA,EAAQC,IAAIC,UANpBtB,EAAAA,oBAAJmB,KAAAC,EAAAC,IAAAE,KACIrB,MAIAA,EAAAA,QAAQiB,qBACJnB,EAAAwB,uBACItB,EAAAiB,KAAA,SAAAC,GACH,MAAA,UAAAA,EAAAC,IAAAI,QAGJzB,EANDwB,oBAAAL,KAAAC,EAAAC,IAAAE,KAOH,MAOQd,EAAAiB,QAAA1B,EAAAD,QAAAG,WACDF,EAAAA,EAAKwB,OAAAA,EAAAA,QAAyBJ,UAEjCpB,EAAA2B,MAND,eAAAzB,EAAA0B,QAOH1B,GAaLJ,EAAOe,UAAUgB,KAAO,SAAeC,GARnC,IAAA9B,EAAM0B,KACFxB,OACHO,EAAAsB,IAAAD,EAAA,oBACD9B,EAAAA,IAAK2B,EAAM,SACXlB,EAAAsB,IAAAD,EAAO5B,UAIXJ,EACQE,0BAAJ8B,EAAAE,qBAEIvB,gBAAYqB,EAAAG,WAIZC,eAAAJ,EAAAK,UAQAnC,EAAKoC,YAAYpC,EAAKqC,eADtBrC,GAEAN,EAAAmB,UAAAgB,KAAArB,KAAAP,KAAA6B,IAMRhC,EAAOe,UAAUyB,0BAA4B,SAD7CN,GAII/B,KAAAsC,KAAKA,sBACL,IAAAvC,EAAIA,KAMJ,OALAA,EAAAA,uBAEAgC,EAAAA,QAAgBQ,SAAAA,EAAQC,GACpBzC,EAAAA,oBAAKG,EAAoBuC,IAAzBjC,EAAAkC,MAAyCA,KAE7C3C,GAIJF,EAAAA,UAAOe,gBAAU+B,SAA2BC,GACxC5C,KAAAsC,KAAKA,oBACL,IAAAvC,EAAIA,KAMJ,OALAA,EAAAA,YAEAS,EAAAA,KAAEqC,EAAKb,SAAAA,EAAOV,GACVvB,EAAAA,SAAKI,GAALK,EAAAkC,MAAsBA,KAE1B3C,GAIJF,EAAAA,UAAOe,eAAUqB,SAA0Ba,GACvC9C,KAAAsC,KAAKA,mBACL,IAAAvC,EAAIA,KAQJ,OAPAA,EAAAA,qBAEAA,EAAAA,UAAKgD,EAEIC,KAAAd,GAFQe,IAAjB,SAAA7B,GAAA,OAAArB,EAAAmD,cAAA1C,EAAAkC,MAAAtB,MAKArB,GAIJF,EAAAA,UAAOe,KAAUoC,SAAgBG,GAU7B,OAAAjB,EAAOA,KATP,SAASkB,EAATC,GACI,OAAAC,EAAAC,YAAMA,EAAFA,YACA,EAEJD,EAAAC,YAAMA,EAAFA,aACA,EAEJ,KAMR1D,EAAAA,UAAOe,cAAUsC,SAAyBM,EAAepC,GAErD,IAAArB,EAAIA,KAEJoB,GAAIA,IAAYC,GAchB,OAZAD,EAAAA,OAAQsC,EAAS1D,eAAK2D,GAClB,IAAJlD,EAAAmD,KAAMA,EAAKxC,SACPpB,EAAAA,YAAK6D,KAAY1C,EAAKE,IAE1BD,EAAAA,QAAQ0C,EAAU9D,gBAAK+D,GACnB,IAAJtD,EAAAmD,KAAMA,EAAKxC,UACPpB,EAAAA,aAAKW,KAAaQ,EAAKE,IAG3BD,EAAAA,KAAQ4C,EAAOhE,SAAKI,EAASiB,SAG7BD,GAKJtB,EAAAA,UAAOe,eAAU8C,SAA0BM,GACvC,IAAAjE,EAAIA,KACJ0D,EAAIA,EAASrC,OACb6C,KAWA,OAVAzD,EAAAA,KAAEqC,EAAKY,SAAAA,EAAQS,IACXC,EAAAA,EAAAA,MAAUzB,EAAM3C,qBAAKqE,KACrBD,KAAME,EAKNF,EAAAA,QAAM1B,EAAU1C,oBAAKG,EAAoBiE,IACzCF,EAAAA,EAASE,IAATA,IAEJF,GAKJpE,EAAAA,UAAOe,qBAAUwD,SAGbE,GAKC,IAAAA,EAAAhD,GACD,MAAKgD,IAAAA,MACD,8BAIHC,KAAAC,UAAAF,IALD,IAAKA,EAAYG,KAA2B,QAApBH,EAAYG,IASxC,MAAA,IAAAC,MAPY,gCASL9D,KAAAA,UAAUkD,IAGb,OAAAQ,GAKIK,EAAAA,UAAAA,gBAAsBzE,SAA2BoB,GACjDsD,IAAAA,EAAAA,KAPAf,EAAUzC,EAAIyC,QASd9D,KAQyB,OAP5BS,EAAAqC,KARDgB,EAAA,SAAAc,EAAAT,IASAS,EAAOC,EAAAA,MAAP7E,EAAAqE,qBAAAO,KAbJN,KAAAH,EAgBAS,EAAAlC,QAAA1C,EAAAG,oBAAAyE,EAAArD,IACAzB,EAAOe,EAAUwB,IAAAA,EAEbrC,EAAAK,kBAAsByE,EAAOvD,IAAAF,EAAAE,KAA7BsD,GAFJ/E,EAAOe,UAAUwB,YAAc,WAO/BvC,IAAAA,EAAOe,KACH,OAAAb,EAAAgD,UAAA8B,OAAA,SAAAC,EAAAtC,GAAA,OAAAzC,EAAAgF,WAAAD,EAAAtC,MAUQ3C,EAAAe,UAAAmE,WAAA,SAAA5D,EAAA6D,GAGR,IAAA,IADCjF,EAAAC,KACDwC,EAAO,EAAPA,EAAAzC,EAAAE,QAAA0B,OAAAa,IAdJ,IAAAzC,EAAAE,QAAAuC,GAAAjC,KAAAR,EAAAoB,GAsBIpB,OAjBQA,EAAK2B,MAYjB,SAVgBP,EAAQC,IAAIE,GACZ,wCAYTV,EAAUuB,QAAAA,KAEF,EAGX3B,OAAEqC,GAMEhD,EAAAe,UAAIqE,YAAW9D,SAAf+D,GACA1E,IAAAA,EAAEqC,KAsCVhD,OArCYE,EAAA2B,MAAA,gBAGAlB,EAAAqC,KAAAqC,EAAKC,SAAAA,GACD,IAAA7D,EAAAH,EAAIiE,IAAAA,GACJD,EAAAA,MAAAA,KAAAA,EAAAA,GACHpF,EAAAsF,aAAA/D,EAAAH,KAEDX,EAAAqC,KAAAqC,EAAA,SAAA/D,GACA,IAAA8D,EAAA9D,EAAAC,IAAAE,GACAvB,EAAAA,KAAAA,EAAKuF,OAAL,SAAgBH,EAAAA,GAAmC,IAAAA,EAAnDpF,EAAAK,kBAAAmF,GAbRJ,IAQYA,EAUZpF,EAAAyF,oBAAAD,GAVqClB,MAmBzCtE,EAAAuF,WAAAH,EAAAF,EAAAlF,EAAA0F,UACO7E,QAAU4E,QAQbzF,EAAA2B,MARJ,gBANQ6C,KAAKC,UAAUzE,EAAK2F,qBAAsB,KAAM,OAkBjD9E,GAICf,EAAAe,UAAA4E,oBAAA,SACAG,GAMI,IAIAC,EAJIC,QAIcA,EACd,OAAA7F,KAAAqF,aAAAO,EAAA5F,KAAAE,oBAAAyF,KAIH9F,EAAAe,UAAAkF,wBAAA,WACD,IAAAC,EAAA/F,KACH,OAAAA,KAhBDgG,iBAAA/C,IAAA,SAAAgD,GAiBA,OAjBAA,EAAUC,SAASlD,KAAK,SAAmBM,EAAGD,GAqB/CzC,IAAAA,EAAUuF,EAAAA,KAAe/E,IACxBgF,EAAAA,KAAAA,IAAJ7C,YACKR,EAAAA,KAAUR,YAAfsD,EAAAxC,EAAAxB,KAAAT,IAGOgF,EAAAA,KAAAA,IAAP7C,YALJF,EAAAxB,KAAA0B,YAQA,OAAA8C,EAAAR,EACehG,EAlBCwG,EAAcR,GACN,EAEL,IAEJ,IAAIjG,MAAMmG,EAAIN,SAAUQ,MAIvCpG,EAAOe,UAAUuF,aAAe,WAC5B,IAAIC,KAIJ,OAHApG,KAAK+C,UAAUR,QAAQ,SAAApB,GACnBiF,EAAYjF,EAAQC,IAAIE,IAAMH,IAE3BiF,aAIIvG","file":"../../../scripts/mvc/history/job-dag.js","sourcesContent":["import GRAPH from \"utils/graph\";\nimport addLogging from \"utils/add-logging\";\n\n// ============================================================================\nvar _super = GRAPH.Graph;\n/** A Directed acyclic Graph built from a history's job data.\n *      Reads in job json, filters and process that json, and builds a graph\n *      using the connections between job inputs and outputs.\n */\nvar JobDAG = function(options) {\n    options = options || {};\n    var self = this;\n    //this.logger = console;\n\n    self.filters = [];\n\n    // instance vars\n    //TODO: needed?\n    self._jobsData = [];\n    self._historyContentsMap = {};\n    self._toolMap = {};\n\n    self._outputIdToJobMap = {};\n    self.noInputJobs = [];\n    self.noOutputJobs = [];\n\n    //TODO: save these?\n    self.filteredSetMetadata = [];\n    self.filteredErroredJobs = [];\n\n    self.dataKeys = [\"jobs\", \"historyContents\", \"tools\"];\n    _super.call(\n        self,\n        true,\n        _.pick(options, self.dataKeys),\n        _.omit(options, self.dataKeys)\n    );\n};\nJobDAG.prototype = new GRAPH.Graph();\nJobDAG.prototype.constructor = JobDAG;\n\n// add logging ability - turn off/on using the this.logger statement above\naddLogging(JobDAG);\n\n// ----------------------------------------------------------------------------\n/** process jobs, options, filters, and any history data, then create the graph */\nJobDAG.prototype.init = function _init(options) {\n    options = options || {};\n\n    var self = this;\n    self.options = _.defaults(options, {\n        excludeSetMetadata: false\n    });\n    self.filters = self._initFilters();\n\n    _super.prototype.init.call(self, options);\n    return self;\n};\n\n/** add job filters based on options */\nJobDAG.prototype._initFilters = function __initFilters() {\n    var self = this;\n    var filters = [];\n\n    if (self.options.excludeSetMetadata) {\n        self.filteredSetMetadata = [];\n        filters.push(function filterSetMetadata(jobData) {\n            if (jobData.job.tool_id !== \"__SET_METADATA__\") {\n                return true;\n            }\n            self.filteredSetMetadata.push(jobData.job.id);\n            return false;\n        });\n    }\n\n    if (self.options.excludeErroredJobs) {\n        self.filteredErroredJobs = [];\n        filters.push(function filterErrored(jobData) {\n            if (jobData.job.state !== \"error\") {\n                return true;\n            }\n            self.filteredErroredJobs.push(jobData.job.id);\n            return false;\n        });\n    }\n\n    // all outputs deleted\n    // all outputs hidden\n\n    if (_.isArray(self.options.filters)) {\n        filters = filters.concat(self.options.filters);\n    }\n    self.debug(\"filters len:\", filters.length);\n    return filters;\n};\n\n/**  */\nJobDAG.prototype.read = function _read(data) {\n    var self = this;\n    if (\n        _.has(data, \"historyContents\") &&\n        _.has(data, \"jobs\") &&\n        _.has(data, \"tools\")\n    ) {\n        // a job dag is composed of these three elements:\n        //  clone the 3 data sources into the DAG, processing the jobs finally using the history and tools\n        self\n            .preprocessHistoryContents(data.historyContents || [])\n            .preprocessTools(data.tools || {})\n            .preprocessJobs(data.jobs || []);\n\n        // filter jobs and create the vertices and edges of the job DAG\n        self.createGraph(self._filterJobs());\n        return self;\n    }\n    return _super.prototype.read.call(this, data);\n};\n\n/**  */\nJobDAG.prototype.preprocessHistoryContents = function _preprocessHistoryContents(\n    historyContents\n) {\n    this.info(\"processing history\");\n    var self = this;\n    self._historyContentsMap = {};\n\n    historyContents.forEach((content, i) => {\n        self._historyContentsMap[content.id] = _.clone(content);\n    });\n    return self;\n};\n\n/**  */\nJobDAG.prototype.preprocessTools = function _preprocessTools(tools) {\n    this.info(\"processing tools\");\n    var self = this;\n    self._toolMap = {};\n\n    _.each(tools, (tool, id) => {\n        self._toolMap[id] = _.clone(tool);\n    });\n    return self;\n};\n\n/** sort the cloned jobs, decorate with tool and history contents info, and store in prop array */\nJobDAG.prototype.preprocessJobs = function _preprocessJobs(jobs) {\n    this.info(\"processing jobs\");\n    var self = this;\n    self._outputIdToJobMap = {};\n\n    self._jobsData = self\n        .sort(jobs)\n        .map(job => self.preprocessJob(_.clone(job)));\n    //console.debug( JSON.stringify( self._jobsData, null, '    ' ) );\n    //console.debug( JSON.stringify( self._outputIdToJobMap, null, '    ' ) );\n    return self;\n};\n\n/** sort the jobs based on update time */\nJobDAG.prototype.sort = function _sort(jobs) {\n    function cmpCreate(a, b) {\n        if (a.create_time > b.create_time) {\n            return 1;\n        }\n        if (a.create_time < b.create_time) {\n            return -1;\n        }\n        return 0;\n    }\n    return jobs.sort(cmpCreate);\n};\n\n/** decorate with input/output datasets and tool */\nJobDAG.prototype.preprocessJob = function _preprocessJob(job, index) {\n    //this.info( 'preprocessJob', job, index );\n    var self = this;\n\n    var jobData = { job: job };\n\n    jobData.inputs = self._processInputs(job);\n    if (_.size(jobData.inputs) === 0) {\n        self.noInputJobs.push(job.id);\n    }\n    jobData.outputs = self._processOutputs(job);\n    if (_.size(jobData.outputs) === 0) {\n        self.noOutputJobs.push(job.id);\n    }\n\n    jobData.tool = self._toolMap[job.tool_id];\n\n    //self.info( '\\t jobData:', jobData );\n    return jobData;\n};\n\n/**\n */\nJobDAG.prototype._processInputs = function __processInputs(job) {\n    var self = this;\n    var inputs = job.inputs;\n    var inputMap = {};\n    _.each(inputs, (input, nameInJob) => {\n        input = _.clone(self._validateInputOutput(input));\n        input.name = nameInJob;\n        // since this is a DAG and we're processing in order of create time,\n        //  the inputs for this job will already be listed in _outputIdToJobMap\n        //  TODO: we can possibly exploit this\n        //console.debug( 'input in _outputIdToJobMap', self._outputIdToJobMap[ input.id ] );\n        input.content = self._historyContentsMap[input.id];\n        inputMap[input.id] = input;\n    });\n    return inputMap;\n};\n\n/**\n */\nJobDAG.prototype._validateInputOutput = function __validateInputOutput(\n    inputOutput\n) {\n    if (!inputOutput.id) {\n        throw new Error(\n            \"No id on job input/output: \",\n            JSON.stringify(inputOutput)\n        );\n    }\n    if (!inputOutput.src || inputOutput.src !== \"hda\") {\n        throw new Error(\n            \"Bad src on job input/output: \",\n            JSON.stringify(inputOutput)\n        );\n    }\n    return inputOutput;\n};\n\n/**\n */\nJobDAG.prototype._processOutputs = function __processOutputs(job) {\n    var self = this;\n    var outputs = job.outputs;\n    var outputMap = {};\n    _.each(outputs, (output, nameInJob) => {\n        output = _.clone(self._validateInputOutput(output));\n        output.name = nameInJob;\n        // add dataset content to jobData\n        output.content = self._historyContentsMap[output.id];\n        outputMap[output.id] = output;\n\n        self._outputIdToJobMap[output.id] = job.id;\n    });\n    return outputMap;\n};\n\n/**  */\nJobDAG.prototype._filterJobs = function __filterJobs() {\n    var self = this;\n    return self._jobsData.filter((j, i) => self._filterJob(j, i));\n};\n\n/**\n */\nJobDAG.prototype._filterJob = function _filterJob(jobData, index) {\n    // apply filters after processing job allowing access to the additional data above inside the filters\n    var self = this;\n    for (var i = 0; i < self.filters.length; i++) {\n        if (!self.filters[i].call(self, jobData)) {\n            self.debug(\n                \"\\t job\",\n                jobData.job.id,\n                \" has been filtered out by function:\\n\",\n                self.filters[i]\n            );\n            return false;\n        }\n    }\n    return true;\n};\n\n/** Walk all the jobs (vertices), attempting to find connections\n *  between datasets used as both inputs and outputs (edges)\n */\nJobDAG.prototype.createGraph = function _createGraph(jobsData) {\n    var self = this;\n    self.debug(\"connections:\");\n    //console.debug( jobsData );\n\n    _.each(jobsData, jobData => {\n        var id = jobData.job.id;\n        self.debug(\"\\t\", id, jobData);\n        self.createVertex(id, jobData);\n    });\n    _.each(jobsData, jobData => {\n        var targetId = jobData.job.id;\n        _.each(jobData.inputs, (input, inputId) => {\n            //console.debug( '\\t\\t target input:', inputId, input );\n            var sourceId = self._outputIdToJobMap[inputId];\n            //console.debug( '\\t\\t source job id:', sourceId );\n            if (!sourceId) {\n                var joblessVertex = self.createJobLessVertex(inputId);\n                sourceId = joblessVertex.name;\n            }\n            //TODO:?? no checking here whether sourceId is actually in the vertex map\n            //console.debug( '\\t\\t creating edge, source:', sourceId, self.vertices[ sourceId ] );\n            //console.debug( '\\t\\t creating edge, target:', targetId, self.vertices[ targetId ] );\n            self.createEdge(sourceId, targetId, self.directed, {\n                dataset: inputId\n            });\n        });\n    });\n    //console.debug( self.toVerticesAndEdges().edges );\n\n    self.debug(\n        \"final graph: \",\n        JSON.stringify(self.toVerticesAndEdges(), null, \"  \")\n    );\n    return self;\n};\n\n/** Return a 'mangled' version of history contents id to prevent contents <-> job id collision */\nJobDAG.prototype.createJobLessVertex = function _createJobLessVertex(\n    contentId\n) {\n    // currently, copied contents are the only history contents without jobs (that I know of)\n    //note: following needed to prevent id collision btwn content and jobs in vertex map\n    var JOBLESS_ID_MANGLER = \"copy-\";\n\n    var mangledId = JOBLESS_ID_MANGLER + contentId;\n    return this.createVertex(mangledId, this._historyContentsMap[contentId]);\n};\n\n/** Override to re-sort (ugh) jobs in each component by update time */\nJobDAG.prototype.weakComponentGraphArray = function() {\n    var dag = this;\n    return this.weakComponents().map(component => {\n        //TODO: this seems to belong above (in sort) - why isn't it preserved?\n        // note: using create_time (as opposed to update_time)\n        //  since update_time for jobless/copied datasets is changes more often\n        component.vertices.sort(function cmpCreate(a, b) {\n            var aCreateTime = a.data.job\n                ? a.data.job.create_time\n                : a.data.create_time;\n\n            var bCreateTime = b.data.job\n                ? b.data.job.create_time\n                : b.data.create_time;\n\n            if (aCreateTime > bCreateTime) {\n                return 1;\n            }\n            if (aCreateTime < bCreateTime) {\n                return -1;\n            }\n            return 0;\n        });\n        return new Graph(dag.directed, component);\n    });\n};\n\nJobDAG.prototype._jobsDataMap = function() {\n    var jobsDataMap = {};\n    this._jobsData.forEach(jobData => {\n        jobsDataMap[jobData.job.id] = jobData;\n    });\n    return jobsDataMap;\n};\n\n// ============================================================================\nexport default JobDAG;\n"]}